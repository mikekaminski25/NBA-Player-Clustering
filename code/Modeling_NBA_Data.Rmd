---
title: "NBA Clustering Project - Tidymodels"
author: "Mike Kaminski"
date: "2023-06-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE,
                      message = FALSE, dpi = 180,
                      fig.width = 10, fig.height = 5)

knitr::opts_knit$set(root.dir = "C:/Users/mikek/Documents/NBA-Player-Clustering")
```

```{r}
library(tidymodels) # broom, dials, parsnip, tune, workflows, yardstick
library(tidyverse) #ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, lubridate
library(tidytext)
library(knitr)
library(stringi)
library(corrr)
```


# Modeling

# PCA and Kmeans
The data is fairly high dimensional, so I'll try reducing the dimensionality by using PCA.

```{r}
NBACleanData <- read_csv("Data/model0611.csv",show_col_types = FALSE) %>% select(-1)
model_df <-  NBACleanData
```
## Preliminary Analysis

I want to see if any of the variables are highly correlated.  Many of the advanced stats (VORP, PER, Win Share, etc.) are formulas that use a combination of other stats in the dataset.  It might be beneficial to remove them.

Corr test
```{r}
corr_df <- model_df %>% select(-c(1:4))

mean(cor(corr_df))
```

Recipe

```{r}
nba_rec_pre <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre <- prep(nba_rec_pre)


```

# from MSFT YT
```{r}
pca_rec <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 2, id = "pca")

pca_estimates <- prep(pca_rec)

features_2d <- pca_estimates %>%
  bake(new_data = NULL)

features_2d %>%
  slice_head(n = 5)

theme_set(theme_light())
options(scipen = 99)

pca_estimates %>%
  tidy(id = "pca", type = "variance") %>%
  filter(terms == "percent variance") 


pca_estimates %>%
  tidy(id = "pca", type = "variance") %>%
  filter(terms == "percent variance") %>%
  ggplot(aes(x = component, y= value)) +
  geom_col(fill = "midnightblue", alpha = 0.7)

features_2d %>%
  ggplot(aes(x = PC1, y = PC2)) +
  geom_point(size = 2, color = "dodgerblue")


nba_features <- recipe(~ ., data = model_df) %>%
  # update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_rm(Year, Player, Pos, Tm) %>%
  step_normalize(all_predictors()) %>%
  prep() %>%
  bake(new_data = NULL)
  
nba_features %>%
  slice_head(n = 5)

set.seed(525)

kcs <- tibble(k=1:15) %>%
  mutate(
    model = map(k, ~ kmeans(x = nba_features, centers = .x,
                            nstart = 20)),
    glanced = map(model, glance)) %>%
  unnest(cols = c(glanced))
  
kcs %>%
  ggplot(aes(x = k, y = tot.withinss)) +
  geom_line(size = 1.2, alpha = 0.5, color = "dodgerblue") +
  geom_point(size = 2, color = "dodgerblue")

```


Tidied
```{r}
tidied_pca_pre <- tidy(nba_prep_pre, 2)


#shows all PCs - it's a bit much
tidied_pca_pre %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component) +
  labs(y = NULL)

#shows just a few PCs
tidied_pca_pre %>%
  filter(component %in% c("PC1", "PC2", "PC3", "PC10")) %>%
  group_by(component) %>%
  top_n(6, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )

# filter(component %in% paste0("PC", 1:10))
```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```
The first two capture about 50% of the variance, top 3 capture 60%, top 5 capture 70%, top 9 capture 80%, top 16 capture 90%.

Capturing 80% of the variance might be a good place to start.  I'll change num_comp to 9 - it defualts to 5
```{r}
nba_rec_pre80 <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 9)

nba_prep_pre80 <- prep(nba_rec_pre80)
```

I'll start with 3 clusters just to see how the data looks.
```{r}
library(tidymodels)

# the template stores the PCA variables
pca_80 <- nba_prep_pre80$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80 %>% select(-c(1:4)), centers = 3)
kclust
```

tidy kclust
```{r}
library(broom)
tidy(kclust)

```

augment kclust
```{r}
augment(kclust, pca_80) %>%
  ggplot(aes(PC1, PC2, color = .cluster)) +
  geom_point()
```

glance kclust
```{r}
glance(kclust)
```

Time to find the optimal number of K
```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_80 %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_80 %>% select(-c(1:4)))
  )

kclusts
```

Look at the elbow plots
```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```

It's a bit difficult to determine the optimal number of k.  An arguement could be made for 3, but it seems unreasonabe to just have 3 positions for NBA players.  I suppose it could be good to have a team with players that all fall in the "best" cluster, but I'd have to look at historically good teams to see what players types they had.

An argument could be made for 6 or 8, especially when we look at the difference in tot.withinss from k to k+1/k+2/k+3  (where does it level off?)  3 still looks like an elbow bend, but I'd prefer not to use that.

I'll try filtering down the data to include less players and see if that changes anything.

## try with less data
From the initial cleaning, I removed playes with mpg of less than 12 mins.  I'll try for less than 20 and re-run
```{r}
model_df_mpg_adj <-  NBACleanData %>%
  filter(MP_pg >= 20)

nba_rec_pre_mpg_adj <- recipe(~ ., data = model_df_mpg_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_mpg_adj <- prep(nba_rec_pre_mpg_adj)

tidied_pca_pre_mpg_adj <- tidy(nba_prep_pre_mpg_adj, 2)

```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_mpg_adj$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_mpg_adj$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```

I can try with 8 PCs

```{r}
nba_rec_pre80_mpg_adj <- recipe(~ ., data = model_df_mpg_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 8)

nba_prep_pre80_mpg_adj <- prep(nba_rec_pre80_mpg_adj)
```

```{r}
# the template stores the PCA variables
pca_80_mpg_adj <- nba_prep_pre80_mpg_adj$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80_mpg_adj %>% select(-c(1:4)), centers = 3)
kclust
```


```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_80_mpg_adj %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_80_mpg_adj %>% select(-c(1:4)))
  )

kclusts
```
Look at the elbow plots
```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```

That really didn't help, still looks like 3 might be optimal, 6 or 8 could work though.

## try with removing advanced stats
Advanced stats are often a formula/combination of the other underlying stats included in the model.  Additionally, points likely impacts FG, FT, ThrPa, TwoPA, and other similar stats. Attempts and makes are also strongly correlated

```{r}
model_df_var_adj <-  NBACleanData %>%
  select(-c(
    contains("_adv"),
    FG_pp, FG_pg, #remove makes, but keep attempts
    FT_pp, FT_pg, #remove makes, but keep attempts
    ThrP_pp, ThrP_pg, #remove makes, but keep attempts
    TwoP_pp, TwoP_pg, #remove makes, but keep attempts
    Reb_T_pg, Reb_T_pp, # remove total rebounds, keep offensive and defensive
    HOF # I just don't want it
    )
  )

nba_rec_pre_var_adj <- recipe(~ ., data = model_df_var_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_var_adj <- prep(nba_rec_pre_var_adj)

tidied_pca_pre_var_adj <- tidy(nba_prep_pre_var_adj, 2)

```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_var_adj$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_var_adj$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```

I can try with 10 PCs

```{r}
nba_rec_pre80_var_adj <- recipe(~ ., data = model_df_var_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 8)

nba_prep_pre80_var_adj <- prep(nba_rec_pre80_var_adj)
```

```{r}
# the template stores the PCA variables
pca_80_var_adj <- nba_prep_pre80_var_adj$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80_var_adj %>% select(-c(1:4)), centers = 3)
kclust
```


```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_80_var_adj %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_80_var_adj %>% select(-c(1:4)))
  )

```
Look at the elbow plots
```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```
Again, 3 seems optimal. 6 or 7 could work tho.


# Just kmeans
My theory is that if kmeans didn't work out so well in a lower dimensional space, it probably won't in a higher dimensional space.  I will attempt to remove correlated variables and try though.
```{r}

model_df %>%
  correlate() %>%
  rearrange() %>%
  shave() %>%
  rplot(shape = 15)

#This lists the highly correlated variables.  I will remove some
model_df %>% 
  correlate() %>%
  stretch() %>%
  filter(abs(r) >=0.7 | abs(r) <=-0.7) %>%
  arrange(desc(abs(r))) %>%
  count(x) %>%
  arrange(desc(n))

model_df %>% 
  select(-contains("_adv")) %>%
  select(-contains("_pg")) %>%
  select(-c(ThrP_pp,TwoP_pp, FT_pp,FG_pp, # attempts and makes are obviously correlated.  We'll keep attempts.
            Reb_T_pp, # Total and Def are correlated, same with Offensive
            FGA_Avg_Dis_sho, # this is correlated with 0-3 ft shots
            FGA_pct_2p_sho,
            PTS_pp,
            TwoP_pct_pp)) %>%
  # select(-c(PTS_pg,PTS_pp,FG_pg,PER_adv,TwoPA_pg,FGA_pct_2p_sho)) %>%
  # select(-c(ThrP_Att_Rt_adv, 
  #           Reb_T_pct_adv, Reb_O_pct_adv,Reb_D_pct_adv,
  #           AST_pct_adv,BLK_pct_adv,
  #           WS_T_adv,BPM_T_adv)) %>% # many of the adv stats overlap
  # select(-c(PTS_pg,PTS_pp)) %>% # Pts and FG overlap, obviously
  # select(-c(ThrP_pg, ThrP_pp,
  #           TwoP_pg,TwoP_pp,
  #           FT_pg,FT_pp,
  #           FG_pg,)) %>% # makes and attempts are correlated, so I'll remove makes
  # select(-c(Reb_T_pg,Reb_T_pp)) %>% # Total rebounds and defensive overlap given that off rebs are less common
  # select(-c(FGA_pct_2p_sho)) %>% #Wthis is correlated with ThrPA_pp.  I want 3 point attempts
  # select(-c(FGA_Avg_Dis_sho)) %>% #Avg distance and 0-3 ft shots are correlated
  # select(-c(FG_pct_T)) %>% #True and Effective are basically the same
  correlate() %>%
  stretch(remove.dups = TRUE) %>%
  filter(abs(r) >=0.7 | abs(r) <=-0.7) %>%
  arrange(desc(abs(r)))
  # count(x) %>%
  # arrange(desc(n))
  
# Many of the adv stats seems to be duplicative or highly correlated with other variables.  I want to keep some, but even these are likely combinations of other variables already included.

model_df_corr <- model_df %>% 
  select(-contains("_adv")) %>%
  select(-contains("_pg")) %>%
  select(-c(ThrP_pp,TwoP_pp, FT_pp,FG_pp, # attempts and makes are obviously correlated.  We'll keep attempts.
            Reb_T_pp, # Total and Def are correlated, same with Offensive
            FGA_Avg_Dis_sho, # this is correlated with 0-3 ft shots
            FGA_pct_2p_sho,
            PTS_pp,
            TwoP_pct_pp)) 

model_df_corr %>%
  correlate() %>%
  rearrange() %>%
  shave() %>%
  rplot(shape = 15) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

  
```

```{r}
nba_rec <- recipe(~ ., data = model_df_corr) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep <- prep(nba_rec)

tidied_pca<- tidy(nba_prep, 2)
```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```

I can try with 8 PCs, which is 70%.  11 is 80%
```{r}
nba_rec <- recipe(~ ., data = model_df_corr) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 8)

nba_prep <- prep(nba_rec)
```



I'll start with 3 clusters just to see how the data looks.
```{r}
# the template stores the PCA variables
pca <- nba_prep$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80 %>% select(-c(1:4)), centers = 3, nstart = 1000, iter.max = 10000)

```



```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca %>% select(-c(1:4)))
  )

```


```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```

Still not very good.  I'll try some other clustering methods



# hierarchical
```{r}
library(workflows)
library(parsnip)
library(tidyclust)
library(tidyverse)
```

```{r}
model_df_hc <- model_df %>%
  filter(Year == 2022) %>%
  select(-c(1:4,80)) 

nba_features <- recipe(~., data = model_df_hc ) %>%
  step_normalize(all_predictors()) %>%
  prep() %>%
  bake(new_data = NULL)


set.seed(42069)
d <- dist(x=nba_features, method = "euclidean")

nba_hclust_complete <- hclust(d, method = "complete")

nba_hclust_average <- hclust(d, method = "average")

nba_hclust_ward <- hclust(d, method = "ward.D2")

```


```{r}
library(factoextra)

fviz_dend(nba_hclust_complete)
fviz_dend(nba_hclust_average)
fviz_dend(nba_hclust_ward)

```

```{r}
library(cluster)

ac_metric <- list(
  complete_ac = agnes(nba_features, metric = "euclidean", method = "complete")$ac,
  average_ac = agnes(nba_features, metric = "euclidean", method = "average")$ac,
  ward_ac = agnes(nba_features, metric = "euclidean", method = "ward")$ac
)

ac_metric
```

```{r}
fviz_nbclust(nba_features, FUNcluster = hcut, method = "wss", k.max = 15)

```

```{r}
fviz_dend(nba_hclust_ward, k = 6)
fviz_dend(nba_hclust_ward, k = 7)
fviz_dend(nba_hclust_ward, k = 8)
```


fviz_dend(nba_hclust_ward, k = 7)