---
title: "NBA Clustering Project - Tidymodels"
author: "Mike Kaminski"
date: "2023-06-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE,
                      message = FALSE, dpi = 180,
                      fig.width = 10, fig.height = 5)

knitr::opts_knit$set(root.dir = "C:/Users/mikek/Documents/NBA-Player-Clustering")
```

```{r}
library(tidymodels) # broom, dials, parsnip, tune, workflows, yardstick
library(tidyverse) #ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, lubridate
library(tidytext)
library(knitr)
library(stringi)
library(corrr)
library(tidyclust)
```


# Modeling

# PCA and Kmeans
The data is fairly high dimensional, so I'll try reducing the dimensionality by using PCA.

```{r}
NBACleanData <- read_csv("Data/model0611.csv",show_col_types = FALSE) %>% select(-1)
model_df <-  NBACleanData
```

## Preliminary Analysis

## PCA
Recipe
```{r}
nba_rec_pre <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre <- prep(nba_rec_pre)

```

Tidied
```{r}
tidied_pca_pre <- tidy(nba_prep_pre, 2)

#shows just a few PCs
tidied_pca_pre %>%
  filter(component %in% c("PC1", "PC2", "PC3", "PC4")) %>%
  group_by(component) %>%
  top_n(6, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )

```

How much variance is being captured?
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```
The first two PCs capture about 50% of the variance, top 3 capture 60%, top 5 capture 70%, top 9 capture 80%, top 16 capture 90%.  16 PCs have a value above 1, so could potentially consider those

Capturing 80% of the variance might be a good place to start.  I'll change num_comp to 9 - it defualts to 5
```{r}
nba_rec_pre80 <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 9)

nba_prep_pre80 <- prep(nba_rec_pre80)
```

Start with 3 clusters just to see how the data looks.
```{r}
library(tidymodels)

# the template stores the PCA variables
pca_80 <- nba_prep_pre80$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80 %>% select(-c(1:4)), centers = 3)
kclust
```

tidy kclust
```{r}
tidy(kclust)
```

augment kclust
```{r}
augment(kclust, pca_80) %>%
  ggplot(aes(PC1, PC2, color = .cluster)) +
  geom_point()
```

glance kclust
```{r}
glance(kclust)
```

Optimal number of K
```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_80 %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_80 %>% select(-c(1:4)))
  )

```

Elbow plots
```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  #change from k = 1 to k = 2
  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  #change from k = 1 to k = 3
  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  #change from k = 1 to k = 4
  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```

It's a bit difficult to determine the optimal number of k.  An argument could be made for 3, but it seems unreasonable to just have 3 positions for NBA players.  I suppose it could be good to have a team with players that all fall in the "best" cluster, but I'd have to look at historically good teams to see which  players types they had.

An argument could be made for 6 or 8, especially when we look at the difference in tot.withinss from k to k+1/k+2/k+3  (where does it level off?)  3 still looks like an elbow bend, but I'd prefer not to use that.

I'll try filtering down the data to include less players and see if that changes anything.


## try with less data
From the initial cleaning, I removed players with mpg of less than 12 mins.  I'll try for less than 20 and re-run
```{r}
model_df_mpg_adj <-  NBACleanData %>%
  filter(MP_pg >= 20)

nba_rec_pre_mpg_adj <- recipe(~ ., data = model_df_mpg_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_mpg_adj <- prep(nba_rec_pre_mpg_adj)

tidied_pca_pre_mpg_adj <- tidy(nba_prep_pre_mpg_adj, 2)

```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_mpg_adj$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_mpg_adj$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```

I can try with 8 PCs

```{r}
nba_rec_pre80_mpg_adj <- recipe(~ ., data = model_df_mpg_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 8)

nba_prep_pre80_mpg_adj <- prep(nba_rec_pre80_mpg_adj)
```

```{r}
# the template stores the PCA variables
pca_80_mpg_adj <- nba_prep_pre80_mpg_adj$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80_mpg_adj %>% select(-c(1:4)), centers = 3)
```


```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_80_mpg_adj %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_80_mpg_adj %>% select(-c(1:4)))
  )
```
Look at the elbow plots
```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```

That really didn't help, still looks like 3 might be optimal, 6 or 8 could work though.


## try with removing advanced stats and a few other stats that are highly correlated
Advanced stats are often a formula/combination of the other underlying stats included in the model.  Additionally, points likely impacts FG, FT, ThrPa, TwoPA, and other similar stats. Attempts and makes are also strongly correlated

```{r}
model_df_var_adj <-  NBACleanData %>%
  select(-c(
    contains("_adv"),
    FG_pp, FG_pg, #remove makes, but keep attempts
    FT_pp, FT_pg, #remove makes, but keep attempts
    ThrP_pp, ThrP_pg, #remove makes, but keep attempts
    TwoP_pp, TwoP_pg, #remove makes, but keep attempts
    Reb_T_pg, Reb_T_pp, # remove total rebounds, keep offensive and defensive
    HOF # I just don't want it
    )
  )

nba_rec_pre_var_adj <- recipe(~ ., data = model_df_var_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_var_adj <- prep(nba_rec_pre_var_adj)

tidied_pca_pre_var_adj <- tidy(nba_prep_pre_var_adj, 2)

```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_var_adj$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_var_adj$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```

I can try with 10 PCs

```{r}
nba_rec_pre80_var_adj <- recipe(~ ., data = model_df_var_adj) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 8)

nba_prep_pre80_var_adj <- prep(nba_rec_pre80_var_adj)
```

```{r}
# the template stores the PCA variables
pca_80_var_adj <- nba_prep_pre80_var_adj$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_80_var_adj %>% select(-c(1:4)), centers = 3)
```


```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_80_var_adj %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_80_var_adj %>% select(-c(1:4)))
  )

```

Look at the elbow plots
```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```
Again, 3 seems optimal. 6 or 7 could work tho.


## try with just stats from each category

###Advanced
```{r}
model_df_adv <-  NBACleanData %>%
  select(Year, Player, Pos, Tm,contains("_adv"))

nba_rec_pre_adv <- recipe(~ ., data = model_df_adv) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_adv <- prep(nba_rec_pre_adv)

tidied_pca_pre_adv <- tidy(nba_prep_pre_adv, 2)
```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_adv$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_adv$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.60))
```
3 70%, 4 80%, 7 90%


###Per 100 possessions
```{r}
model_df_adv <-  NBACleanData %>%
  select(Year, Player, Pos, Tm,contains("_pp"))

nba_rec_pre_adv <- recipe(~ ., data = model_df_adv) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_adv <- prep(nba_rec_pre_adv)

tidied_pca_pre_adv <- tidy(nba_prep_pre_adv, 2)
```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_adv$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_adv$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```
4 70%, 6 80%, 9 90%


### Shooting
```{r}
model_df_adv <-  NBACleanData %>%
  select(Year, Player, Pos, Tm,contains("_sho"))

nba_rec_pre_adv <- recipe(~ ., data = model_df_adv) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_adv <- prep(nba_rec_pre_adv)

tidied_pca_pre_adv <- tidy(nba_prep_pre_adv, 2)
```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_adv$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_adv$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))
```
Not ideal


###Per Game
```{r}
model_df_pg <-  NBACleanData %>%
  select(Year, Player, Pos, Tm,contains("_pg"))

nba_rec_pre_adv <- recipe(~ ., data = model_df_pg) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

nba_prep_pre_pg<- prep(nba_rec_pre_adv)

tidied_pca_pre_pg <- tidy(nba_prep_pre_pg, 2)
```

Check to see how much variance is being captured
```{r, fig.width= 14, fig.height = 3}
sdev <- nba_prep_pre_pg$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca_pre_pg$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.70))
```
2 70%, 3 80%, 6 90%

Per game stats give us the best values, capturing 72% of the variance in the first 2 PCs

I'll start with 3 clusters just to see how the data looks.
```{r}
# the template stores the PCA variables
pca_pg <- nba_prep_pre_pg$template %>%
    mutate(Year = as.character(Year),
         Player = as.character(Player),
         Pos = as.character(Pos),
         Tm = as.character(Tm)) %>%
  as_tibble()

set.seed(525)

kclust <- kmeans(pca_pg %>% select(-c(1:4)), centers = 3, nstart = 1000, iter.max = 10000)

```


```{r}
kclusts <- 
  tibble(k = 1:15) %>%
  mutate(
    kclust = map(k, ~ kmeans(pca_pg %>% select(-c(1:4)), .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, pca_pg %>% select(-c(1:4)))
  )

```

```{r}
kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)

kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss-lead(tot.withinss,n=2))) +
  geom_line(alpha = 0.8) +
  geom_point(size = 2)


kclusts %>%
  unnest(glanced) %>%
  ggplot(aes(k, tot.withinss)) +
  # geom_line(alpha = 0.8) +
  # geom_point(size = 2) +

  geom_line(aes(k, tot.withinss-lead(tot.withinss)), alpha = 0.8 ) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss)),size = 2,color = "red") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=2)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=2)),size = 2, color = "blue") +

  geom_line(aes(k, tot.withinss-lead(tot.withinss,n=3)), alpha = 0.8) +
  geom_point(aes(k, tot.withinss-lead(tot.withinss,n=3)),size = 2, color = "green")
```
It's still not looking great, so I'll explore other ways to cluster

# Hierarchical

- High dimensional data will run slowly in Hierarchical clustering, so I'll use PCA
- 9 PCs make up 80% of the variance, so I'll start with that.  It could still run pretty slow, but we'll see.

```{r}
# recipe
nba_rec <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 10)

#prep -  needed for tidied_pca and plot
nba_prep <- prep(nba_rec)

tidied_pca <- tidy(nba_prep,2)

sdev <- nba_prep$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

tibble(component = unique(tidied_pca$component),
       percent_var = percent_variation) %>%
  filter(component %in% paste0("PC", 1:20)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col(position = "stack") +
    geom_text(aes(label = scales::percent((round(percent_var,4))),
            vjust = -0.5)
            ) +
  geom_text(aes(label = scales::percent(cumsum(percent_var)),
            vjust = -1.5)
            ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,.35))

# new dataframe
nba_bake <- bake(nba_prep, new_data = NULL) %>%
  mutate(across(where(is.factor), as.character)) 


```


## from MSFT YT
```{r}
pca_rec <- recipe(~ ., data = model_df) %>%
  update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 2, id = "pca")

pca_estimates <- prep(pca_rec)

features_2d <- pca_estimates %>%
  bake(new_data = NULL)

features_2d %>%
  slice_head(n = 5)

theme_set(theme_light())
options(scipen = 99)

pca_estimates %>%
  tidy(id = "pca", type = "variance") %>%
  filter(terms == "percent variance") 


pca_estimates %>%
  tidy(id = "pca", type = "variance") %>%
  filter(terms == "percent variance") %>%
  ggplot(aes(x = component, y= value)) +
  geom_col(fill = "midnightblue", alpha = 0.7)

features_2d %>%
  ggplot(aes(x = PC1, y = PC2)) +
  geom_point(size = 2, color = "dodgerblue")


nba_features <- recipe(~ ., data = model_df) %>%
  # update_role(Year, Player, Pos, Tm, new_role = "id") %>%
  step_rm(Year, Player, Pos, Tm) %>%
  step_normalize(all_predictors()) %>%
  prep() %>%
  bake(new_data = NULL)
  
nba_features %>%
  slice_head(n = 5)

set.seed(525)

kcs <- tibble(k=1:15) %>%
  mutate(
    model = map(k, ~ kmeans(x = nba_features, centers = .x,
                            nstart = 20)),
    glanced = map(model, glance)) %>%
  unnest(cols = c(glanced))
  
kcs %>%
  ggplot(aes(x = k, y = tot.withinss)) +
  geom_line(size = 1.2, alpha = 0.5, color = "dodgerblue") +
  geom_point(size = 2, color = "dodgerblue")

```

```{r}

```

I'll start by sampling from the data set to see which hierarchical method is the most balanced
```{r}
model_df_hc <- nba_bake %>%
  sample_n(1000) %>%
  select(-c(1:4)) 

set.seed(42069)

# Distance between observations matrix
d <- dist(x=model_df_hc, method = "euclidean")

# Hierarchical clustering using Complete Linkage
nba_hclust_complete <- hclust(d, method = "complete")

# Hierarchical clustering using Average Linkage
nba_hclust_average <- hclust(d, method = "average")

# Hierarchical clustering using Ward Linkage
nba_hclust_ward <- hclust(d, method = "ward.D2")

```

Dendrogram of each
```{r}
library(factoextra)

fviz_dend(nba_hclust_complete,main = "Complete")
fviz_dend(nba_hclust_average, main = "Average Linkage")
fviz_dend(nba_hclust_ward, main = "Ward")

```

The below looks at the agglomerative coefficent, which measures clustering structure of the dataset.  A value closer to 1 means more balanced.

```{r}
library(cluster)

ac_metric <- list(
  complete_ac = agnes(model_df_hc, metric = "euclidean", method = "complete")$ac,
  average_ac = agnes(model_df_hc, metric = "euclidean", method = "average")$ac,
  ward_ac = agnes(model_df_hc, metric = "euclidean", method = "ward")$ac
)

ac_metric
```
Ward's is the closest to one, so that's the method that we'll use.


This will give us the optimal number of clusters.  Similar to the methods used earlier in the analysis with k-means
```{r}
fviz_nbclust(model_df_hc, FUNcluster = hcut, method = "wss", k.max = 15)

```
Again, this gives us 3, even in a lower dimensional space.


```{r}
fviz_dend(nba_hclust_ward, k = 6)
fviz_dend(nba_hclust_ward, k = 7)
fviz_dend(nba_hclust_ward, k = 8)
fviz_dend(nba_hclust_ward, k = 9)
```

```{r}

# Use all the data
model_df_hc_full <- nba_bake %>%
  select(-c(1:4)) 

set.seed(42069)

# Distance between observations matrix
d <- dist(x=model_df_hc_full, method = "euclidean")


# Hierarchical clustering using Ward Linkage
nba_hclust_ward <- hclust(d, method = "ward.D2")

# Group data into 7 clusters
results_hclust <- tibble(
  cluster_id = cutree(nba_hclust_ward, k = 7)) %>% 
  mutate(cluster_id = factor(cluster_id)) %>%
  cbind(nba_bake)

results_hclust %>% 
  slice_head(n = 5)


```

